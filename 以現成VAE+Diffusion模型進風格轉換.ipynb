{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["YxXmwKyAFrEH","S-zzr0qMF4RH","ez_7iWmdGIxx","DoMqaG1NGUVN"],"authorship_tag":"ABX9TyNG8402TWk8TxW7Uj+F7Nn/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 安裝套件、匯入所需函式庫"],"metadata":{"id":"YxXmwKyAFrEH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tiq6ofPI_nE"},"outputs":[],"source":["!pip install torch torchvision matplotlib diffusers\n","\n","# 匯入函式庫\n","import torch\n","from diffusers import AutoencoderKL\n","from torchvision import transforms\n","from torchvision.transforms import ToPILImage\n","from PIL import Image\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","source":["# 下載預訓練模型"],"metadata":{"id":"S-zzr0qMF4RH"}},{"cell_type":"code","source":["\n","# 加載預訓練的 VAE 模型\n","print(\"Loading VAE model from Hugging Face...\")\n","model_id = \"shi-labs/versatile-diffusion\"\n","vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n","vae.eval()\n","print(\"Model loaded successfully!\")\n","\n","# 圖片預處理\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),  # 模型需要的輸入尺寸\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])  # 標準化至 [-1, 1]\n","])\n","\n"],"metadata":{"id":"78060O4FF4es"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 讀取、顯示圖片"],"metadata":{"id":"ez_7iWmdGIxx"}},{"cell_type":"code","source":["def load_image(image_path):\n","    \"\"\"載入並預處理圖片\"\"\"\n","    image = Image.open(image_path).convert('RGB')\n","    original_size = image.size  # 記錄原圖尺寸\n","    return transform(image).unsqueeze(0), original_size\n","\n","def show_image(tensor, title=\"\"):\n","    \"\"\"顯示圖片\"\"\"\n","    image = tensor.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n","    image = (image * 0.5 + 0.5)  # 反標準化至 [0, 1]\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.title(title)\n","    plt.show()\n","\n","# 載入圖片\n","content_image_path = \"/content/orig.jpeg\"  # 原始圖片路徑\n","style_image_path = \"/content/starry_night.jpg\"  # 風格圖片路徑\n","\n","content_image, content_size = load_image(content_image_path)  # 載入原圖並記錄尺寸\n","style_image, _ = load_image(style_image_path)  # 載入風格圖\n","\n","# 顯示原圖和風格圖\n","show_image(content_image, title=\"Content Image\")\n","show_image(style_image, title=\"Style Image\")\n","\n"],"metadata":{"id":"qLULaPDDFMXU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 風格轉換、顯示風格轉換結果"],"metadata":{"id":"DoMqaG1NGUVN"}},{"cell_type":"code","source":["# 編碼和解碼（風格融合）\n","with torch.no_grad():\n","    content_latents = vae.encode(content_image).latent_dist.sample()\n","    style_latents = vae.encode(style_image).latent_dist.sample()\n","\n","    alpha = 0.5  # 風格比例\n","    mixed_latents = alpha * style_latents + (1 - alpha) * content_latents\n","\n","    # 解碼生成\n","    generated_image = vae.decode(mixed_latents).sample\n","\n","# 調整生成圖片的尺寸與原圖一致\n","resized_image = torch.nn.functional.interpolate(\n","    generated_image, size=(content_size[1], content_size[0]), mode=\"bilinear\", align_corners=False\n",")\n","\n","# 顯示生成結果\n","show_image(resized_image)\n","\n","# 保存生成圖片\n","#output_image = ToPILImage()((resized_image.squeeze(0) * 0.5 + 0.5).clamp(0, 1))\n","#output_image.save(\"/content/generated_image.jpg\")\n","#print(\"Generated image saved as 'generated_image.jpg'\")"],"metadata":{"id":"H0D-uhFjGVLr"},"execution_count":null,"outputs":[]}]}