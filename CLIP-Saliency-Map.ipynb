{"cells":[{"cell_type":"markdown","id":"5deb9e1b-083b-406d-82fd-545e6c380298","metadata":{"id":"5deb9e1b-083b-406d-82fd-545e6c380298"},"source":["# 以CLIP與顯著圖來實作多模態問答\n"]},{"cell_type":"markdown","source":["## CLIP與顯著圖\n"],"metadata":{"id":"JPViepAnbyJj"},"id":"JPViepAnbyJj"},{"cell_type":"markdown","source":["\n","- CLIP（對比語言-圖像預訓練，Contrastive Language–Image Pre-training）是一個可以同時處理圖像和文本的神經網絡。它經過訓練來預測隨機文本片段是否能準確描述某張圖像。\n","- 顯著性圖是一種視覺化技術，用於突出顯示圖像中的關鍵區域。例如，它可以用來解釋圖像分類的預測對於特定標籤的意義。"],"metadata":{"id":"h13Yrt8pzhNV"},"id":"h13Yrt8pzhNV"},{"cell_type":"markdown","id":"3b59b6fe-cf2e-4f31-9ed6-034cbec4d05b","metadata":{"id":"3b59b6fe-cf2e-4f31-9ed6-034cbec4d05b"},"source":["## 安裝所需套件"]},{"cell_type":"code","execution_count":null,"id":"4608996e","metadata":{"id":"4608996e"},"outputs":[],"source":["%pip install -q \"openvino>=2023.1.0\"\n","%pip install -q --extra-index-url https://download.pytorch.org/whl/cpu transformers torch gradio"]},{"cell_type":"markdown","source":["## 匯入所需套件"],"metadata":{"id":"mR6UWzJ-ccSy"},"id":"mR6UWzJ-ccSy"},{"cell_type":"code","execution_count":null,"id":"7554390c-8e7a-47a9-ad37-82d0febc87ed","metadata":{"id":"7554390c-8e7a-47a9-ad37-82d0febc87ed"},"outputs":[],"source":["from pathlib import Path\n","from typing import Tuple, Union, Optional\n","from urllib.request import urlretrieve\n","\n","from matplotlib import colors\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import requests\n","import torch\n","import tqdm\n","from PIL import Image\n","from transformers import CLIPModel, CLIPProcessor"]},{"cell_type":"markdown","id":"9e5014b5-fd40-4951-b489-aecdd5484e5c","metadata":{"id":"9e5014b5-fd40-4951-b489-aecdd5484e5c"},"source":["## CLIP模型"]},{"cell_type":"markdown","source":["\n","- 使用 OpenAI 提供的 CLIP 模型版本 clip-vit-base-patch16，這是一個基於 Vision Transformer（ViT）的 CLIP 模型。"],"metadata":{"id":"LrVPNX4vzm4v"},"id":"LrVPNX4vzm4v"},{"cell_type":"code","execution_count":null,"id":"897d05b9-eb04-4837-9049-80b622009512","metadata":{"id":"897d05b9-eb04-4837-9049-80b622009512"},"outputs":[],"source":["# 初始化CLIP模型與處理器\n","# CLIP模型由OpenAI開發，用於文本與圖像的多模態學習\n","model_checkpoint = \"openai/clip-vit-base-patch16\"\n","\n","model = CLIPModel.from_pretrained(model_checkpoint).eval()\n","processor = CLIPProcessor.from_pretrained(model_checkpoint)"]},{"cell_type":"markdown","id":"97fa373b-b745-4909-9d99-09d49512e1dc","metadata":{"id":"97fa373b-b745-4909-9d99-09d49512e1dc"},"source":["## 定義函式\n"]},{"cell_type":"markdown","source":["\n","- get_random_crop_params 生成隨機裁剪的座標與尺寸。\n","- get_crop_image 獲取實際裁剪的圖像部分\n","- update_saliency_map 根據計算出的相似度更新顯著性圖。\n","- cosine_similarity 函數則是上述餘弦相似度公式的實作。"],"metadata":{"id":"np4zku4IzsUy"},"id":"np4zku4IzsUy"},{"cell_type":"code","execution_count":null,"id":"091b34ca-7722-4541-8def-d325582a6c95","metadata":{"id":"091b34ca-7722-4541-8def-d325582a6c95"},"outputs":[],"source":["def get_random_crop_params(\n","    image_height: int, image_width: int, min_crop_size: int\n",") -> Tuple[int, int, int, int]:\n","    crop_size = np.random.randint(min_crop_size, min(image_height, image_width))\n","    x = np.random.randint(image_width - crop_size + 1)\n","    y = np.random.randint(image_height - crop_size + 1)\n","    return x, y, crop_size\n","\n","\n","def get_cropped_image(\n","    im_tensor: np.array, x: int, y: int, crop_size: int\n",") -> np.array:\n","    return im_tensor[\n","        y : y + crop_size,\n","        x : x + crop_size,\n","        ...\n","    ]\n","\n","\n","def update_saliency_map(\n","    saliency_map: np.array, similarity: float, x: int, y: int, crop_size: int\n",") -> None:\n","    saliency_map[\n","        y : y + crop_size,\n","        x : x + crop_size,\n","    ] += similarity\n","\n","\n","def cosine_similarity(\n","    one: Union[np.ndarray, torch.Tensor], other: Union[np.ndarray, torch.Tensor]\n",") -> Union[np.ndarray, torch.Tensor]:\n","    return one @ other.T / (np.linalg.norm(one) * np.linalg.norm(other))"]},{"cell_type":"markdown","id":"84713076-9a19-45ef-b200-6a3eeb4d4770","metadata":{"id":"84713076-9a19-45ef-b200-6a3eeb4d4770"},"source":["## 設定圖片及查詢提示詞\n"]},{"cell_type":"markdown","source":["- 先將圖片上傳至左側資料夾\n","- 修改程式中的問題描述\n","- 再修改程式中的圖檔名稱\n","- 最後執行程式格"],"metadata":{"id":"jty0wwemzwDB"},"id":"jty0wwemzwDB"},{"cell_type":"code","execution_count":null,"id":"d9e6ff21-1e66-4318-b1af-82f1858c9034","metadata":{"id":"d9e6ff21-1e66-4318-b1af-82f1858c9034"},"outputs":[],"source":["from pathlib import Path\n","from PIL import Image\n","import numpy as np\n","\n","# 定義參數\n","n_iters = 300  # 迭代次數，用於生成顯著圖\n","min_crop_size = 50  # 最小裁剪尺寸\n","\n","# 問題文字\n","query = \"Write your question here.\"\n","\n","# 使用本地圖片\n","image_path = Path(\"/content/圖片名稱.jpg\")\n","image = Image.open(image_path)\n","im_tensor = np.array(image)\n","\n","# 圖片尺寸\n","x_dim, y_dim = image.size\n","\n","print(f\"Image size: {x_dim}x{y_dim}\")"]},{"cell_type":"markdown","id":"56b3b797-c80b-4fe8-a1ee-88c90abab97e","metadata":{"id":"56b3b797-c80b-4fe8-a1ee-88c90abab97e"},"source":["## 文本及圖像預處理像"]},{"cell_type":"code","execution_count":null,"id":"19ae13d0-9bee-4b40-b8e2-a9df0192428f","metadata":{"id":"19ae13d0-9bee-4b40-b8e2-a9df0192428f"},"outputs":[],"source":["# 使用CLIP處理器將圖像和文本轉換為模型輸入格式\n","inputs = processor(text=[query], images=[im_tensor], return_tensors=\"pt\")\n","with torch.no_grad():\n","    results = model(**inputs)\n","results.keys()"]},{"cell_type":"markdown","id":"5129b1c2-8b67-48f0-b986-02fa24701beb","metadata":{"id":"5129b1c2-8b67-48f0-b986-02fa24701beb"},"source":["## 計算相似度"]},{"cell_type":"code","execution_count":null,"id":"5a206b42-a22e-4e01-b89a-1375fdc99271","metadata":{"id":"5a206b42-a22e-4e01-b89a-1375fdc99271"},"outputs":[],"source":["# 計算初始的查詢文本與整體圖像的相似度\n","initial_similarity = cosine_similarity(results.text_embeds, results.image_embeds).item()\n","# 初始化顯著性圖 (saliency map)，其大小與圖像相同\n","saliency_map = np.zeros((y_dim, x_dim))\n","\n","# 設定程序的迭代次數\n","for _ in tqdm.notebook.tqdm(range(n_iters)):\n","    # 隨機生成圖像裁剪的參數，包括裁剪起點 (x, y) 和裁剪大小\n","    x, y, crop_size = get_random_crop_params(y_dim, x_dim, min_crop_size)\n","    # 根據生成的參數裁剪圖像\n","    im_crop = get_cropped_image(im_tensor, x, y, crop_size)\n","\n","    # 使用 CLIP 處理器對裁剪的圖像和查詢文本進行預處理，轉換為模型輸入格式\n","    inputs = processor(text=[query], images=[im_crop], return_tensors=\"pt\")\n","    with torch.no_grad():\n","        # 將預處理的輸入傳入模型，計算裁剪圖像與查詢文本的相似度\n","        results = model(**inputs)\n","\n","    # 計算裁剪圖像的相似度與初始相似度的差異\n","    similarity = cosine_similarity(results.text_embeds, results.image_embeds).item() - initial_similarity\n","    # 使用計算出的相似度更新顯著性圖中對應的區域\n","    update_saliency_map(saliency_map, similarity, x, y, crop_size)\n"]},{"cell_type":"markdown","id":"5ec576f1-a85e-486c-bc4a-92fc5489f6bc","metadata":{"id":"5ec576f1-a85e-486c-bc4a-92fc5489f6bc"},"source":["## 繪製顯著圖"]},{"cell_type":"code","execution_count":null,"id":"9b9f23dc-e59b-4cd3-bf42-239e045dae66","metadata":{"id":"9b9f23dc-e59b-4cd3-bf42-239e045dae66"},"outputs":[],"source":["plt.figure(dpi=150)\n","plt.imshow(saliency_map, norm=colors.TwoSlopeNorm(vcenter=0), cmap='jet')\n","plt.colorbar(location=\"bottom\")\n","plt.title(f'Query: \\\"{query}\\\"')\n","plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"markdown","id":"7163e299-ab02-43e7-b49c-a7295001abbb","metadata":{"id":"7163e299-ab02-43e7-b49c-a7295001abbb"},"source":["## 叠合原圖與顯著圖"]},{"cell_type":"code","execution_count":null,"id":"7f3b5066-c0b6-4cd8-8f86-70f07c076046","metadata":{"id":"7f3b5066-c0b6-4cd8-8f86-70f07c076046"},"outputs":[],"source":["def plot_saliency_map(image_tensor: np.ndarray, saliency_map: np.ndarray, query: Optional[str]) -> None:\n","    # 設置圖像的 DPI（解析度）\n","    fig = plt.figure(dpi=150)\n","\n","    # 顯示原始圖像\n","    plt.imshow(image_tensor)\n","\n","    # 疊加顯著性圖\n","    plt.imshow(\n","        saliency_map,\n","        norm=colors.TwoSlopeNorm(vcenter=0),  # 設置顯著性圖的標準化範圍，以 0 為中心\n","        cmap=\"jet\",  # 使用 \"jet\" 色彩映射，顯示不同的顏色區分強度\n","        alpha=0.5,  # 設置透明度，確保可以同時看到原始圖像和顯著性圖\n","    )\n","\n","    # 如果有查詢文本，將其作為標題顯示\n","    if query:\n","        plt.title(f'Query: \"{query}\"')\n","\n","    # 關閉圖像的座標軸顯示\n","    plt.axis(\"off\")\n","\n","    plt.show()\n","    #return fig  # 返回生成的圖像對象\n","\n","# 調用函數以顯示顯著性圖\n","plot_saliency_map(im_tensor, saliency_map, query)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/openvinotoolkit/openvino_notebooks/blob/main/notebooks/232-clip-language-saliency-map/232-clip-language-saliency-map.ipynb","timestamp":1737356699304}],"collapsed_sections":["JPViepAnbyJj","3b59b6fe-cf2e-4f31-9ed6-034cbec4d05b","mR6UWzJ-ccSy","9e5014b5-fd40-4951-b489-aecdd5484e5c","97fa373b-b745-4909-9d99-09d49512e1dc","84713076-9a19-45ef-b200-6a3eeb4d4770","56b3b797-c80b-4fe8-a1ee-88c90abab97e","5129b1c2-8b67-48f0-b986-02fa24701beb","5ec576f1-a85e-486c-bc4a-92fc5489f6bc","7163e299-ab02-43e7-b49c-a7295001abbb"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"openvino_notebooks":{"imageUrl":"https://user-images.githubusercontent.com/29454499/218967961-9858efd5-fff2-4eb0-bde9-60852f4b31cb.JPG","tags":{"categories":["Model Demos","Explainable AI"],"libraries":[],"other":[],"tasks":["Feature Extraction"]}},"toc-autonumbering":false,"toc-showcode":false,"toc-showmarkdowntxt":false,"toc-showtags":false,"vscode":{"interpreter":{"hash":"cec18e25feb9469b5ff1085a8097bdcd86db6a4ac301d6aeff87d0f3e7ce4ca5"}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}