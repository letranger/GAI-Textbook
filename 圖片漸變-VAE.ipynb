{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FEWZxrtJgNZ5whASZCVStC3fEy-YYBF6","timestamp":1733385204314}],"collapsed_sections":["Sst7b6XurG3Y","paVHFL-MrNIm","I8H8sPYHrgOA","8hYMxNFQruLW"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 定義變分自編碼器（VAE）"],"metadata":{"id":"Sst7b6XurG3Y"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import os\n","\n","# 定義變分自編碼器（VAE）\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(True)\n","        )\n","        self.fc_mu = nn.Linear(64 * 7 * 7, 256)\n","        self.fc_logvar = nn.Linear(64 * 7 * 7, 256)\n","        self.fc_decode = nn.Linear(256, 64 * 7 * 7)\n","\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n","            nn.Sigmoid()\n","        )\n","\n","    def encode(self, x):\n","        h = self.encoder(x).view(-1, 64 * 7 * 7)\n","        mu = self.fc_mu(h)\n","        logvar = self.fc_logvar(h)\n","        return mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        h = self.fc_decode(z).view(-1, 64, 7, 7)\n","        return self.decoder(h)\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar"],"metadata":{"id":"UG4mpLUkrMy6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"HZgAmSgBzh-u"}},{"cell_type":"markdown","source":["# 訓練變分自編碼器（VAE）"],"metadata":{"id":"paVHFL-MrNIm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nz1njcukmA0Q"},"outputs":[],"source":["# 訓練 VAE\n","def train_vae(vae, dataloader, num_epochs=20, learning_rate=1e-3):\n","    reconstruction_loss_fn = nn.BCELoss(reduction='sum')\n","    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n","\n","    vae.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for images, _ in dataloader:\n","            images = images.to(device)\n","\n","            # 前向傳播\n","            reconstructed, mu, logvar = vae(images)\n","            reconstruction_loss = reconstruction_loss_fn(reconstructed, images)\n","            kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","            loss = reconstruction_loss + kld_loss\n","\n","            # 反向傳播和優化\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        avg_loss = running_loss / len(dataloader.dataset)\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n","\n","    # 保存模型\n","    torch.save(vae.state_dict(), 'vae_mnist.pth')\n","    print(\"Model saved as 'vae_mnist.pth'\")\n","\n","# 加載模型\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","vae = VAE().to(device)\n","\n","# 訓練數據集\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n","\n","# 訓練 VAE\n","train_vae(vae, dataloader, num_epochs=10)\n","\n","vae.eval()"]},{"cell_type":"markdown","source":["# 觀察資料集中的圖片\n"],"metadata":{"id":"I8H8sPYHrgOA"}},{"cell_type":"code","source":["# 從數據集中選擇兩張圖片，顯示出來\n","image1, _ = dataset[3] #這裡從資料集中挑選出第4張圖片(資料集中的圖片編號由0開始)\n","image2, _ = dataset[4] #這裡從資料集中挑選出第5張圖片\n","fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","axes[0].imshow(image1.squeeze(), cmap='gray')\n","axes[0].axis('off')\n","axes[1].imshow(image2.squeeze(), cmap='gray')\n","axes[1].axis('off')\n","plt.show()"],"metadata":{"id":"PMgAUVZqrt64"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 進行image1到image2的圖片漸變"],"metadata":{"id":"8hYMxNFQruLW"}},{"cell_type":"code","source":["with torch.no_grad():\n","    # 編碼兩張圖片得到隱變量\n","    mu1, _ = vae.encode(image1)\n","    mu2, _ = vae.encode(image2)\n","\n","    # 進行漸變，生成 10 張漸變圖片\n","    fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n","    for i, alpha in enumerate(torch.linspace(0, 1, steps=10)):\n","        z = mu1 * (1 - alpha) + mu2 * alpha\n","        generated_image = vae.decode(z).cpu().squeeze(0)\n","        axes[i].imshow(generated_image.permute(1, 2, 0).squeeze(), cmap='gray')\n","        axes[i].axis('off')\n","\n","    plt.show()"],"metadata":{"id":"-Uuh8arwrPB9"},"execution_count":null,"outputs":[]}]}