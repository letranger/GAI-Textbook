{"cells":[{"cell_type":"markdown","id":"15cea7c2-08e9-4756-bd2a-bf3a206a53dc","metadata":{"id":"15cea7c2-08e9-4756-bd2a-bf3a206a53dc"},"source":["# 以GAN生成MNIST手寫數字\n","- 這段程式使用生成對抗網路（GAN）生成類似於MNIST數據集中手寫數字的假數據。\n","- MNIST數據集中包含數字0到9的手寫數字圖像，目的是生成與此數據相似的假數據。"]},{"cell_type":"markdown","source":["## 安裝所需函式庫"],"metadata":{"id":"HJ0XGKcqA-PU"},"id":"HJ0XGKcqA-PU"},{"cell_type":"code","source":["## 安裝所需函式庫\n","!pip install numpy\n","!pip install matplotlib\n","!pip install torch\n","!pip install torchvision"],"metadata":{"id":"fTBsJQKF74Kk"},"id":"fTBsJQKF74Kk","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 載入所需函式庫"],"metadata":{"id":"5sdZXfg27yA8"},"id":"5sdZXfg27yA8"},{"cell_type":"code","execution_count":null,"id":"832a09ee-a365-4f10-a538-2712eb4c933d","metadata":{"id":"832a09ee-a365-4f10-a538-2712eb4c933d"},"outputs":[],"source":["import math\n","import pickle as pkl\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","id":"39970055-91f1-4679-b47a-792fab843d7e","metadata":{"id":"39970055-91f1-4679-b47a-792fab843d7e"},"source":["## 載入資料並進行探索"]},{"cell_type":"code","execution_count":null,"id":"9fd6cb73-dcd1-476c-aecd-406d120dadd1","metadata":{"id":"9fd6cb73-dcd1-476c-aecd-406d120dadd1"},"outputs":[],"source":["# 定義數據轉換操作：將數據轉換為Tensor格式\n","transform = transforms.Compose([transforms.ToTensor()])\n","train_ds = datasets.MNIST(root='./data',  # 數據保存的路徑\n","                          train=True,     # 指定為訓練數據集\n","                          download=True,  # 如果數據未下載，則下載\n","                          transform=transform)"]},{"cell_type":"code","execution_count":null,"id":"5c39d7bf-7317-4321-9e53-79607517f989","metadata":{"id":"5c39d7bf-7317-4321-9e53-79607517f989"},"outputs":[],"source":["# 輸出數據的基本資訊\n","print(train_ds.data.shape)  # 訓練數據的形狀\n","print(train_ds.targets.shape)  # 訓練數據對應的標籤\n","print(train_ds.classes)  # 數據集的分類\n","print(train_ds.data[0])  # 第一個圖像的像素值"]},{"cell_type":"markdown","source":["## 分批讀入、檢查圖像資料"],"metadata":{"id":"OmFbaHmbUy8R"},"id":"OmFbaHmbUy8R"},{"cell_type":"code","execution_count":null,"id":"151dfa0b-569b-443b-a228-0bc2dd3cb493","metadata":{"id":"151dfa0b-569b-443b-a228-0bc2dd3cb493"},"outputs":[],"source":["\n","dl = DataLoader(dataset=train_ds,  # 資料集\n","                shuffle=True,      # 隨機打亂資料集順序\n","                batch_size=64)     # 每批次的大小"]},{"cell_type":"code","execution_count":null,"id":"689af3ec-8bdf-44ee-afd3-041ad9845036","metadata":{"id":"689af3ec-8bdf-44ee-afd3-041ad9845036"},"outputs":[],"source":["# 檢查讀入圖像資料\n","image_batch = next(iter(dl))  # 獲取一個批次的數據\n","print(len(image_batch), type(image_batch))  # 輸出批次的長度與類型\n","print(image_batch[0].shape)  # 圖像批次的形狀\n","print(image_batch[1].shape)  # 對應標籤的形狀"]},{"cell_type":"code","execution_count":null,"id":"0cdbfe38-af0d-4024-bd3d-9b91a576176e","metadata":{"id":"0cdbfe38-af0d-4024-bd3d-9b91a576176e"},"outputs":[],"source":["## ----------------------------------------------------------------------------\n","## 資料視覺化\n","## ----------------------------------------------------------------------------\n","\n","def display_images(images, n_cols=4, figsize=(12, 6)):\n","    \"\"\"\n","    功能：在網格中顯示一組圖像\n","\n","    參數\n","    ----------\n","    images: Tensor\n","        包含要顯示的圖像的張量\n","    n_cols: int\n","        網格中的列數\n","    figsize: tuple\n","        圖像的大小\n","    \"\"\"\n","    plt.style.use('ggplot')  # 使用ggplot樣式\n","    n_images = len(images)  # 獲取圖像數量\n","    n_rows = math.ceil(n_images / n_cols)  # 計算行數\n","    plt.figure(figsize=figsize)  # 設置圖像大小\n","    for idx in range(n_images):  # 遍歷所有圖像\n","        ax = plt.subplot(n_rows, n_cols, idx + 1)\n","        image = images[idx]\n","        # 調整維度為 H x W x C\n","        image = image.permute(1, 2, 0)\n","        cmap = 'gray' if image.shape[2] == 1 else plt.cm.viridis  # 根據通道數決定顏色\n","        ax.imshow(image, cmap=cmap)\n","        ax.set_xticks([])  # 移除X軸標籤\n","        ax.set_yticks([])  # 移除Y軸標籤\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 顯示圖像，網格列數為8\n","display_images(images=image_batch[0], n_cols=8)"]},{"cell_type":"markdown","id":"c2f47858-06cf-4e7d-a204-7ed33fda9b33","metadata":{"id":"c2f47858-06cf-4e7d-a204-7ed33fda9b33"},"source":["## 定義GAN網路結構"]},{"cell_type":"markdown","id":"3628845f-5c52-4848-8ba2-54ab6f639386","metadata":{"id":"3628845f-5c52-4848-8ba2-54ab6f639386"},"source":["### 定義判別器網路"]},{"cell_type":"code","execution_count":null,"id":"e73a0e41-af62-4607-82aa-d1f8822efc7c","metadata":{"id":"e73a0e41-af62-4607-82aa-d1f8822efc7c"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","\n","        # 判別器網路結構：逐步下採樣輸入，生成二元輸出\n","        self.fc1 = nn.Linear(in_features=in_features, out_features=128)\n","        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.2)  # 使用LeakyReLU激活函數\n","        self.fc2 = nn.Linear(in_features=128, out_features=64)\n","        self.leaky_relu2 = nn.LeakyReLU(negative_slope=0.2)\n","        self.fc3 = nn.Linear(in_features=64, out_features=32)\n","        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.2)\n","        self.fc4 = nn.Linear(in_features=32, out_features=out_features)\n","        self.dropout = nn.Dropout(0.3)  # 添加Dropout防止過擬合\n","\n","    def forward(self, x):\n","        # 將輸入圖像展平\n","        batch_size = x.shape[0]\n","        x = x.view(batch_size, -1)\n","        # 前向傳播\n","        x = self.fc1(x)\n","        x = self.leaky_relu1(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.leaky_relu2(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        x = self.leaky_relu3(x)\n","        x = self.dropout(x)\n","        logit_out = self.fc4(x)  # 最後一層輸出為logits\n","\n","        return logit_out"]},{"cell_type":"markdown","id":"d0f606cf-e9e3-4821-94ae-abf1d7e5c99a","metadata":{"id":"d0f606cf-e9e3-4821-94ae-abf1d7e5c99a"},"source":["### 定義生成器網路"]},{"cell_type":"code","execution_count":null,"id":"727408f5-76b9-4ef1-8755-029b7d96abeb","metadata":{"id":"727408f5-76b9-4ef1-8755-029b7d96abeb"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(Generator, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","\n","        # 生成器網路結構：逐步上採樣輸入，生成與判別器輸入大小一致的圖像\n","        self.fc1 = nn.Linear(in_features=in_features, out_features=32)\n","        self.relu1 = nn.LeakyReLU(negative_slope=0.2)  # 使用LeakyReLU激活函數\n","        self.fc2 = nn.Linear(in_features=32, out_features=64)\n","        self.relu2 = nn.LeakyReLU(negative_slope=0.2)\n","        self.fc3 = nn.Linear(in_features=64, out_features=128)\n","        self.relu3 = nn.LeakyReLU(negative_slope=0.2)\n","        self.fc4 = nn.Linear(in_features=128, out_features=out_features)\n","        self.dropout = nn.Dropout(0.3)  # 添加Dropout防止過擬合\n","        self.tanh = nn.Tanh()  # 使用tanh函數壓縮輸出到[-1,1]範圍\n","\n","    def forward(self, x):\n","        # 前向傳播\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        x = self.relu3(x)\n","        x = self.dropout(x)\n","        x = self.fc4(x)\n","        tanh_out = self.tanh(x)  # 輸出為tanh函數壓縮的數據\n","\n","        return tanh_out"]},{"cell_type":"markdown","id":"264df085-aa20-4686-a992-57c603a9c224","metadata":{"id":"264df085-aa20-4686-a992-57c603a9c224"},"source":["## 定義損失函數"]},{"cell_type":"code","execution_count":null,"id":"b6938e67-2de2-424b-8d23-339302dde4ed","metadata":{"id":"b6938e67-2de2-424b-8d23-339302dde4ed"},"outputs":[],"source":["def real_loss(predicted_outputs, loss_fn, device):\n","    \"\"\"\n","    計算對於真實資料的損失\n","\n","    參數\n","    ----------\n","    predicted_outputs: Tensor\n","        判別器對真實資料的預測輸出\n","    loss_fn: nn.Module\n","        使用的損失函數（例如 BCEWithLogitsLoss）\n","    device: str\n","        訓練設備（例如 'cpu' 或 'cuda'）\n","\n","    返回值\n","    -------\n","    real_loss: Tensor\n","        真實數據的損失值\n","    \"\"\"\n","    batch_size = predicted_outputs.shape[0]\n","    # 將目標設為全1，因為判別器應該預測為真實\n","    targets = torch.ones(batch_size).to(device)\n","    real_loss = loss_fn(predicted_outputs.squeeze(), targets)\n","    return real_loss\n","\n","\n","def fake_loss(predicted_outputs, loss_fn, device):\n","    \"\"\"\n","    計算對於假資料的損失\n","\n","    參數\n","    ----------\n","    predicted_outputs: Tensor\n","        判別器對假數據的預測輸出\n","    loss_fn: nn.Module\n","        使用的損失函數（例如 BCEWithLogitsLoss）\n","    device: str\n","        訓練設備（例如 'cpu' 或 'cuda'）\n","\n","    返回值\n","    -------\n","    fake_loss: Tensor\n","        假數據的損失值\n","    \"\"\"\n","    batch_size = predicted_outputs.shape[0]\n","    # 將目標設為全0，因為判別器應該預測為假\n","    targets = torch.zeros(batch_size).to(device)\n","    fake_loss = loss_fn(predicted_outputs.squeeze(), targets)\n","    return fake_loss"]},{"cell_type":"markdown","id":"7b7f1066-48b2-498c-9889-c25a608d0fbe","metadata":{"id":"7b7f1066-48b2-498c-9889-c25a608d0fbe"},"source":["## 訓練網路\n","在訓練過程中，需要為判別器和生成器分別定義優化器。"]},{"cell_type":"code","execution_count":null,"id":"fc3a0e7f-79f2-4b29-8b8e-be64ffd79912","metadata":{"id":"fc3a0e7f-79f2-4b29-8b8e-be64ffd79912"},"outputs":[],"source":["# 初始化一組隨機的潛在向量，用於視覺化生成器\n","z_size = 200 #潛在向量的大小\n","z = np.random.uniform(-1, 1, size=(16, z_size))\n","plt.imshow(z, cmap='gray')\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"7721b017-4c95-43bb-8f47-422851c3d5af","metadata":{"id":"7721b017-4c95-43bb-8f47-422851c3d5af"},"outputs":[],"source":["# 訓練迴圈函數\n","def train_minst_gan(d, g, d_optim, g_optim, loss_fn, dl, n_epochs, device, verbose=False):\n","    \"\"\"\n","    訓練GAN模型，包括生成器和判別器。\n","\n","    參數\n","    ----------\n","    d: Discriminator\n","        判別器模型\n","    g: Generator\n","        生成器模型\n","    d_optim: torch.optim.Optimizer\n","        判別器的優化器\n","    g_optim: torch.optim.Optimizer\n","        生成器的優化器\n","    loss_fn: nn.Module\n","        損失函數（例如 BCEWithLogitsLoss）\n","    dl: DataLoader\n","        MNIST數據集的數據加載器\n","    n_epochs: int\n","        訓練的輪數\n","    device: str\n","        訓練設備（例如 'cpu' 或 'cuda'）\n","    verbose: bool\n","        是否顯示訓練過程中的詳細資訊\n","\n","    返回值\n","    -------\n","    d_losses: list\n","        判別器的損失隨時間變化的記錄\n","    g_losses: list\n","        生成器的損失隨時間變化的記錄\n","    \"\"\"\n","    print(f'開始在 [{device}] 上訓練...')\n","\n","    # 初始化一個固定的潛在向量，用於生成器的進展視覺化\n","    fixed_z = np.random.uniform(-1, 1, size=(16, z_size))\n","    fixed_z = torch.from_numpy(fixed_z).float().to(device)\n","\n","    # 儲存生成的樣本與損失記錄\n","    fixed_samples = []\n","    d_losses = []\n","    g_losses = []\n","\n","    # 將模型移動到指定設備\n","    d = d.to(device)\n","    g = g.to(device)\n","\n","    for epoch in range(n_epochs):\n","        print(f'Epoch [{epoch+1}/{n_epochs}]:')\n","        d.train()\n","        g.train()\n","        d_running_batch_loss = 0\n","        g_running_batch_loss = 0\n","\n","        # 遍歷DataLoader中的每個批次\n","        for curr_batch, (real_images, _) in enumerate(dl):\n","            # 移動資料到指定設備\n","            real_images = real_images.to(device)\n","\n","            ## 訓練判別器\n","            d_optim.zero_grad()  # 重置梯度\n","            real_images = (real_images * 2) - 1  # 將像素範圍從 [0,1] 映射到 [-1,1]\n","            d_real_logits_out = d(real_images)\n","            d_real_loss = real_loss(d_real_logits_out, loss_fn, device)\n","\n","            with torch.no_grad():\n","                # 生成一批假資料\n","                z = np.random.uniform(-1, 1, size=(dl.batch_size, z_size))\n","                z = torch.from_numpy(z).float().to(device)\n","                fake_images = g(z)\n","            d_fake_logits_out = d(fake_images)\n","            d_fake_loss = fake_loss(d_fake_logits_out, loss_fn, device)\n","\n","            # 判別器的總損失\n","            d_loss = d_real_loss + d_fake_loss\n","            d_loss.backward()\n","            d_optim.step()\n","\n","            d_running_batch_loss += d_loss\n","\n","            ## 訓練生成器\n","            g_optim.zero_grad()\n","            z = np.random.uniform(-1, 1, size=(dl.batch_size, z_size))\n","            z = torch.from_numpy(z).float().to(device)\n","            fake_images = g(z)\n","            g_logits_out = d(fake_images)\n","            g_loss = real_loss(g_logits_out, loss_fn, device)\n","            g_loss.backward()\n","            g_optim.step()\n","\n","            g_running_batch_loss += g_loss\n","\n","            # 每400批次顯示訓練狀態\n","            if curr_batch % 400 == 0 and verbose:\n","                print(f'\\tBatch [{curr_batch}/{len(dl)}] - d_loss: {d_loss.item():.6f}, g_loss: {g_loss.item():.6f}')\n","\n","        # 記錄每輪的損失\n","        d_losses.append(d_running_batch_loss.item() / len(dl))\n","        g_losses.append(g_running_batch_loss.item() / len(dl))\n","\n","        print(f'epoch_d_loss: {d_losses[-1]:.6f} \\tepoch_g_loss: {g_losses[-1]:.6f}')\n","\n","        # 用固定的潛在向量生成假資料並儲存\n","        g.eval()\n","        fixed_samples.append(g(fixed_z).detach().cpu())\n","\n","    # 儲存生成的假資料\n","    with open('fixed_samples.pkl', 'wb') as f:\n","        pkl.dump(fixed_samples, f)\n","\n","    return d_losses, g_losses"]},{"cell_type":"code","execution_count":null,"id":"303fdc7b-5996-45a7-b9f0-bfc64b9a2d24","metadata":{"id":"303fdc7b-5996-45a7-b9f0-bfc64b9a2d24"},"outputs":[],"source":["##\n","## 開始訓練模型\n","##\n","\n","# 設定GAN訓練參數\n","d = Discriminator(in_features=784, out_features=1)  # 初始化判別器\n","g = Generator(in_features=200, out_features=784)  # 初始化生成器\n","d_optim = optim.Adam(d.parameters(), lr=0.002)  # 判別器優化器\n","g_optim = optim.Adam(g.parameters(), lr=0.002)  # 生成器優化器\n","loss_fn = nn.BCEWithLogitsLoss()  # 損失函數\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'  # 設置訓練設備\n","n_epochs = 50  # 訓練回合數\n","\n","# 指定訓練設備（檢查系統有沒有GPU可以用）\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 訓練GAN模型\n","import time  # 引入時間模組\n","\n","start_time = time.time()  # 開始計時\n","print(\"開始訓練GAN模型、計時...\")\n","d_losses, g_losses = train_minst_gan(d, g, d_optim, g_optim, loss_fn, dl, n_epochs, device)\n","end_time = time.time()  # 結束計時\n","\n","# 輸出訓練時間\n","print(f\"訓練時間: {end_time - start_time:.2f} seconds\")"]},{"cell_type":"markdown","source":["## 查看模型效能\n"],"metadata":{"id":"e3EojOj0ZQGN"},"id":"e3EojOj0ZQGN"},{"cell_type":"code","execution_count":null,"id":"ad1bcbf2-681b-4687-b773-72a15cadc125","metadata":{"id":"ad1bcbf2-681b-4687-b773-72a15cadc125"},"outputs":[],"source":["# 視覺化訓練損失\n","plt.plot(d_losses, label='Discriminator Loss')\n","plt.plot(g_losses, label='Generator Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["## 建立各回合的生成器圖像"],"metadata":{"id":"DaVf6evYZZV1"},"id":"DaVf6evYZZV1"},{"cell_type":"code","execution_count":null,"id":"2e55287b-02e1-4cc9-a521-dbd2d86316ad","metadata":{"id":"2e55287b-02e1-4cc9-a521-dbd2d86316ad"},"outputs":[],"source":["##\n","## 視覺化生成器生成的圖像\n","\n","def show_generated_images(epoch, n_cols=8):\n","    \"\"\"\n","    顯示指定訓練輪數生成器生成的假數據圖像\n","\n","    參數\n","    ----------\n","    epoch: int\n","        要顯示的訓練輪數\n","    n_cols: int\n","        每行顯示的圖像數量\n","\n","    返回值\n","    -------\n","    None\n","    \"\"\"\n","    # 載入之前儲存的生成樣本\n","    with open('fixed_samples.pkl', 'rb') as f:\n","        saved_data = pkl.load(f)\n","    epoch_data = saved_data[epoch-1]  # 獲取指定輪數的假數據\n","    # 將生成的數據範圍從 [-1, 1] 映射回 [0, 1]\n","    epoch_data = (epoch_data + 1) / 2\n","    # 調整數據形狀為 (批次大小, 通道數, 高度, 寬度)\n","    batch_size, channel, height, width = len(epoch_data), 1, 28, 28\n","    image_batch = epoch_data.view(batch_size, channel, height, width)\n","    # 顯示圖像\n","    display_images(images=image_batch, n_cols=n_cols, figsize=(12, 4))"]},{"cell_type":"markdown","source":["## 觀察生成器的生成結果\n"],"metadata":{"id":"paJWCBSAZiiT"},"id":"paJWCBSAZiiT"},{"cell_type":"code","execution_count":null,"id":"d79418bc-b2c1-4de7-bd6f-9610551921b5","metadata":{"id":"d79418bc-b2c1-4de7-bd6f-9610551921b5"},"outputs":[],"source":["# 在指定輪數顯示生成的圖像\n","show_generated_images(epoch=1, n_cols=8)"]},{"cell_type":"code","execution_count":null,"id":"522b8800-4fd9-41f6-9d5b-ce7d9df840ff","metadata":{"id":"522b8800-4fd9-41f6-9d5b-ce7d9df840ff"},"outputs":[],"source":["show_generated_images(epoch=10, n_cols=8)"]},{"cell_type":"code","execution_count":null,"id":"eebbd219-2b3f-4ee9-874c-45e0186b9c31","metadata":{"id":"eebbd219-2b3f-4ee9-874c-45e0186b9c31"},"outputs":[],"source":["show_generated_images(epoch=50, n_cols=8)"]},{"cell_type":"code","execution_count":null,"id":"f49b0841-fe28-4097-940b-3055829925d3","metadata":{"id":"f49b0841-fe28-4097-940b-3055829925d3"},"outputs":[],"source":["show_generated_images(epoch=100, n_cols=8)"]},{"cell_type":"code","source":["show_generated_images(epoch=200, n_cols=8)"],"metadata":{"id":"DtmV0WsaRlUc"},"id":"DtmV0WsaRlUc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_generated_images(epoch=300, n_cols=8)"],"metadata":{"id":"8sk4E3DjRmak"},"id":"8sk4E3DjRmak","execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_generated_images(epoch=400, n_cols=8)"],"metadata":{"id":"Qz8abbYyRpGN"},"id":"Qz8abbYyRpGN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_generated_images(epoch=500, n_cols=8)"],"metadata":{"id":"ZOFYcHm2RrHd"},"id":"ZOFYcHm2RrHd","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["HJ0XGKcqA-PU","5sdZXfg27yA8","39970055-91f1-4679-b47a-792fab843d7e","OmFbaHmbUy8R","3628845f-5c52-4848-8ba2-54ab6f639386","d0f606cf-e9e3-4821-94ae-abf1d7e5c99a","264df085-aa20-4686-a992-57c603a9c224","7b7f1066-48b2-498c-9889-c25a608d0fbe","e3EojOj0ZQGN","DaVf6evYZZV1","paJWCBSAZiiT"]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}